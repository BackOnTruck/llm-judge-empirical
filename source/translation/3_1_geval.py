from model_api import Model_API
import json, re
from config import DIR, RESPONDED_DATA, GEVAL_RES, gpt4o, CRITERIA
from concurrent.futures import as_completed, ThreadPoolExecutor
from tqdm import tqdm

#! varies per task
# system prompt; disabled for LLMs not supporting it
system_prompt = "You are an expert software developer."

#! varies per task; evaluation steps generated by 3_1_geval_prep.py
# user prompts; EN template: for LLMs, 1 response; CN template: for humans, 3 responses
template = f"""Given a code snippet in {{}}, a developer has translated it into {{}}.
You are to evaluate the quality of the translated code, without considering the quality of the original code.
Note that the developer may provide explanations or comments around the translated code, which should not affect your judgment of the code.

## Original {{}} Code:
```
{{}}
```

## Translated {{}} Code:
```
{{}}
```

You should analyze the translated code based on the following aspects:
{CRITERIA}

To evaluate the translated code, follow these steps:

### Step 1: Readability & Idiomatic Usage
1. Examine Code Structure: Review the overall structure and formatting of the translated code. Check if it follows the target language's conventions, such as indentation, naming conventions, and organization.
2. Language Patterns: Look for idiomatic patterns that are characteristic of the target language. This could include specific constructs, functions, or methods commonly used by developers in that language.
3. Comments and Documentation: Assess if the translations use inline comments or documentation effectively as per the norms of the target language (these do not affect the evaluation but should adhere to norms if present).
4. Clear and Concise: Ensure that the code is expressed as clearly and concisely as possible, avoiding unnecessary complexity.
5. Rate: Based on these criteria, assign a readability and idiomatic usage score from the provided scale (1 to 5).

### Step 2: Consistency with Source
1. Functionality Comparison: Compare the functionality of the translated code with the source. Check if the code performs the same operations and achieves the intended outcomes.
2. Logic and Flow: Examine if the logic and flow of the code remain consistent between the source and translation. Look for differences in control structures, algorithm steps, or data processing.
3. Handling of Data Types and Structures: Make sure that any data types, structures, or objects have been correctly translated to equivalent constructs in the target language.
4. Edge Cases and Errors: Verify if any edge cases or error-handling mechanisms present in the source have been addressed in the translated code.
5. Rate: Based on these criteria, assign a consistency score from the provided scale (1 to 5).

### Provide Overall Feedback
- Comments: Offer specific feedback on areas of excellence or improvement for both aspects.
- Suggestions: If applicable, provide suggestions for enhancing readability or correcting any consistency issues.


Now, please fill out the evaluation form by giving the overall score FIRST in the format of `X/5` before scoring each aspect and making explanations.
## Evaluation form:
- Overall score: """

N = 20
def solve(index: int, query: str, bar: tqdm):
    model = Model_API(system_prompt, gpt4o)
    try:
        replies = model.generate(query, T=1.0, N=N, maxlen=20)
        tqdm.write(f">>> Success: {sum(len(reply) for reply in replies)} characters")

    except Exception as e:
        replies = None
        tqdm.write(f">>> Failed: ({type(e)}) {e}")

    bar.update()
    matches = list(filter(lambda x: x, [re.findall(r'([0-5](?:\.\d+)?)', reply) for reply in replies]))
    if not matches:
        matches = [[-1]]

    return index, model.message, sum(float(match[0]) for match in matches) / len(matches), matches

def main():
    with open(f'{DIR}/{RESPONDED_DATA[0]}') as fin:
        batch = []
        for line in fin:
            js = json.loads(line)
            src_lang, tgt_lang = js['lang'].split(', ')
            #! params vary per task
            batch += [template.format(src_lang, tgt_lang, src_lang, js['input'], tgt_lang, js['output'])]

    with tqdm(total=len(batch), desc='>>> Progress') as bar, ThreadPoolExecutor(max_workers=40) as ex:
        futures = as_completed([ex.submit(solve, idx, sample, bar) for idx, sample in enumerate(batch)])

    path = f'{DIR}/{GEVAL_RES}'
    with open(path, 'w') as fout, open(f'{path}.log', 'w') as flog, open(f'{path}.txt', 'w') as fscores:
        for _, message, score, all_scores in sorted([future.result() for future in futures]):
            print(json.dumps(message), file=flog)
            print(score, file=fout)
            print(json.dumps(all_scores), file=fscores)

if __name__ == '__main__':
    main()
